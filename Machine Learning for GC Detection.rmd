---
title: "Machine Learning for GC Detection"
author: "William Patterson"
date: "June 18, 2019"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(pROC)

```

# Status 

- Data Downlaoded: 6/18/19 11:45am
- Data Location: H:\Machine Learning for CDS
- Last edited: 6/18/19

## Known Bugs

- Many, many incomplete cases make the data difficult to deal with. Working through that as of 7/5/19.

## About the data

- There should be 14,664 records as of the time of writing
- Clinic records span from 1/13/12 to the present (6/18/19)

# Cleaning the data
For this project, we will aim to isolate gay men. This can be more difficult to parse from clinic data than it originally may seem. I want to pick out those that publicly identify as gay (or at least identify as gay on the clinic intake form) as well as those who may not choose to identify as gay but are MSM (based on behavorial characteristics collected from the clinic intake form). I will isolate specific variables: `sex_partners.factor`, `male_anal_sex_both`, `male_anal_insertive`, and `male_anal_receptive`. I can make two separate subsets and take the union of the sets to find the total sample of MSM. 

```{r Loading and Subsetting Data}
### Reading in data and cleaning ----
library(dplyr)

# run script from REDCap to get data from TheMiriamHospitalHIV_R_2019-06-18_1142.r
source("H:/Machine Learning for CDS/TheMiriamHospitalHIV_R_2019-06-18_1142.r")

# I'll be looking at MSM. Must subset based on behavorial factors
# create a set that identify as gay
gay_identified <- data %>% 
  filter(sex_partners.factor == "I am a man who only has sex with other men" | 
           sex_partners.factor == "I am a man who has sex with both men and women")

# create a set that behaves as msm
msm_identified <- data %>% 
  filter(gender.factor == "Male" & (male_anal_sex_both >= 1 |
                                      male_anal_insertive >= 1 | 
                                      male_anal_receptive >= 1))

# take the union of these two sets
total_msm <- union(gay_identified, msm_identified)
```

Here we find that the total number of MSM in the sample is `r nrow(total_msm)`. This is suspiciously similar to the number isolated in the `gay_identified` subset (n = `r nrow(gay_identified)`), so we can do an additional checksum below.

```{r Checksum}
nrow(setdiff(gay_identified, total_msm)) == 0
```

Here we take the difference of the two sets and check that the number of returned records is 0 (i.e. we're not losing anyone). This checks out.

# Getting a feel for the data

Originally, I planned to do this sort of analysis with ~14,000 data points. Unfortunately, I did not take into account the sexual orientation of participants (which may complicate the agent based modelling arm of my thesis). Regardless, I can still attempt to do an analysis.

```{r Data Exploration, echo = FALSE}
### Initial Data Vis ----
library(RColorBrewer)

hist(data$age, main="Age of Clinic Patients", xlab="Age (years)")

boxplot((data %>% 
           filter(data$total_partners <= 120))$total_partners, 
            main="Number of Sexual Partners")

counts=table(data$race.factor, data$gender.factor)

barplot(counts[,0:2], 
        main="Race", 
        beside = TRUE, 
        col=brewer.pal(n=9, name="Set1"), 
        legend=rownames(counts))

counts2=table(data$sexual_identify.factor)

barplot(counts2, 
        main="Sexual Orientation", 
        beside = TRUE, 
        col=brewer.pal(n=8, name="Set1"), 
        legend=rownames(counts2), 
        xaxt="n")
```

#  Analysis of all Clinic Data

## Creating our Labels

Before we start splitting, we need to make sure we have identified a proper label for this data. In this early stage, the goal is to predict Gonorrhea at any location (oral, anal, or genital). We will first have to create a column that indicates any presence of Gonorrhea.

We can repeat this process for other STIs. Phil suggested that it might help with my unbalanced data case if I combine the presence of any STI into a master label (`master_sti`).

```{r Label Design}
library(dplyr)
library(tidyr)

# collate STI data for all people
data$master_gc <- as.vector(ifelse((data$gc_result == 1 | 
                                      data$oral_gc == 1 | 
                                      data$rectal_gc == 1), 1, 0))

data$master_ct <- as.vector(ifelse((data$ct_result == 1 | 
                                      data$oral_ct == 1 | 
                                      data$rectal_ct == 1), 1, 0))

data$master_syph <- as.vector(ifelse(data$sy_result, 1, 0))

data$master_sti <- as.vector(ifelse((data$master_ct == 1 |
                                       data$master_gc == 1 | 
                                       data$master_syph== 1), 1, 0))

# collate STI data for MSM
total_msm$master_gc <- as.vector(ifelse((total_msm$gc_result == 1 | 
                                           total_msm$oral_gc == 1 | 
                                           total_msm$rectal_gc == 1), 
                                        1, 0))

total_msm$master_ct <- as.vector(ifelse((total_msm$ct_result == 1 | 
                                           total_msm$oral_ct == 1 | 
                                           total_msm$rectal_ct == 1), 
                                        1, 0))

total_msm$master_syph <- as.vector(ifelse((total_msm$sy_result == 1 
                                           & total_msm$syphilis_stage != 0), 1, 0))

total_msm$master_sti <- as.vector(ifelse((total_msm$master_ct == 1 |
                                           total_msm$master_gc == 1|
                                           total_msm$master_syph== 1),
                                  1, 0))

total_msm$gc_ct_master <- as.vector(ifelse((total_msm$master_ct == 1 | 
                                              total_msm$master_gc == 1),
                                  1, 0))

# additional corrections for syphilis data
total_msm$master_sti[is.na(total_msm$master_sti) & 
                       is.na(total_msm$master_gc) &
                       is.na(total_msm$master_ct) &
                       total_msm$master_syph == 0] <- 0

total_msm$master_sti[is.na(total_msm$master_sti) & 
                       total_msm$master_gc == 0 &
                       total_msm$master_ct == 0 &
                       is.na(total_msm$master_syph)] <- 0


# what do our proportions look like?
prop.table(table(total_msm$master_sti))

# library(DMwR) #Data Mining with R
# 
# total_msm$master_sti <- as.factor(total_msm$master_sti)
# total_msm$hiv_risk <- as.factor(total_msm$hiv_risk)
# total_msm <- SMOTE(master_sti ~ ., total_msm, perc.over = 200)
# total_msm$master_sti <- as.numeric(total_msm$master_sti)
# prop.table(table(total_msm$master_sti))

```

Here we have made the assumptions that if we tested for 2 of the three determinants (e.g. GC and CT but not Syphilis) and both of the tests came back negative, then we declare them as STI negative.

The `master_sti` is not a well balanced case! We need to continue with the corrections.

Our label column should be free of any NA values (otherwise it can't be used in the analysis).

## Visualizing the subset

Above we subsetted all MSM from the clinic. As we will be performing a supervised learning approach, we needed a label for our data. The `master_sti` label shown above will serve as a label that provides us balanced positive and negative classes.

We should first take a peak at our data.

```{r}
library(ggplot2)
library(plyr)
library(cowplot)

total_msm$master_sti_factor <- mapvalues(as.factor(total_msm$master_sti), 
                                         from = c(0, 1), 
                                         to=c("Negative","Positive"))

# graphs of age based on class status
ggplot(drop_na(total_msm, master_sti_factor), aes(x=age, fill=master_sti_factor)) +
  geom_histogram(position="identity", color="white") +
  labs(title="Age of MSM Reporting to Clinic", 
       x="Age (years)", 
       y="Count", 
       fill="STD Status") +
  theme_classic()

# are the number of total partners signficantly different between those positive and negative?
ggplot(drop_na(total_msm, master_sti_factor), aes(x=total_partners, fill=master_sti_factor)) +
  geom_histogram(color="white") +
  facet_grid(master_sti_factor ~ .) +
  xlim(0, 50) +
  labs(title="Number of Total Partners of MSM Reporting to Clinic", 
       x="Number of Partners", 
       y="Count", 
       fill="STD Status") +
  theme_classic()

# does perceived hiv risk change with age?
total_msm$hiv_risk_factor <- mapvalues(as.factor(total_msm$hiv_risk), 
                                       from = 0:4, 
                                       to=c("None","Low","Medium","High","Not Applicable"))

ggplot(drop_na(total_msm, hiv_risk), aes(group=hiv_risk_factor, 
                                         x=hiv_risk_factor, 
                                         fill=hiv_risk_factor, 
                                         y=age)) +
  geom_boxplot() +
  labs(title="HIV Risk vs. Age", 
       x="HIV Risk",
       y="Age") +
  theme_classic()

# does number of sex partners change with age?
ggplot(total_msm, aes(x=total_partners, y=age)) +
  geom_bin2d() +
  xlim(0, 50) +
  theme_classic() +
  labs(title="Total number of partners vs. Age", 
       x="Total Number of Partners", y="Age", fill="Number of Partners") +
  scale_fill_gradient(low="yellow",high="red")

# how does percieved hiv risk correlate with instances of CAI?
ggplot(drop_na(total_msm, hiv_risk), aes(group=hiv_risk_factor, 
                                         x=hiv_risk_factor, 
                                         y=male_anal_sex_condom,
                                         fill=hiv_risk_factor)) +
  geom_boxplot() +
  ylim(0,75)

```

## Machine Learning

XGBoost is a kind of gradient boosting. It is a sequential method, therefore it cannot be parallelized efficiently. This is okay as our data sample is quite small. This could, however, present some issues if we were to scale up the scope of the experiment.

### Cleaning the data

Our first step is to clean the data of any *leaky* features (e.g. those that could incidentally reveal the label of the data). Examples include `gc_result` and `ct_result`.

```{r clean_leaky_data}
# eliminate rows that leak label info
total_msm <- select(total_msm, -c('sy_result','master_gc','master_ct','master_syph','gc_result',
                'ct_result', 'oral_gc', 'oral_ct','rectal_gc','rectal_ct',
                'syphilis_stage','rpr_result','treponema_igg_result','rpr_result', 'hiv_result',
                'rpr_titer','tppa_result', 'gc_ct_master'))

# second pass to remove .factor columns
total_msm <- total_msm[, -grep("factor", colnames(total_msm)),]
```

We can also drop rows that have a low response rate or are irrelevant to prediction.

```{r}
total_msm <- select(total_msm, -c('gender_other','sexual_identity_other', 'other_state', 'males_vaginal_sex', 'male_vaginal_sex_condom',
                                  'male_vaginal_sex_hiv', 'male_vaginal_sex_idu', 'female_vaginal_sex_msm', 'sex_assigned_birth',
                                  'other_reason_prep','hcv_result_rna','share_needles','last_inject','prep_discussed',
                                  'prep_not_discussed_why', 'sexual_identify', 'std_name_other'))
total_msm <- total_msm[-c(0:82), ] # had to drop first 82 rows as they did not have data on sexual history

```

Rows that aren't applicable (i.e. `female_oral_sex` for men who only have sex with men), should be filled with 0.

```{r unapplicable_rows}
total_msm[is.na(total_msm$female_oral_sex),]$female_oral_sex <- 0
total_msm[is.na(total_msm$female_sex_vaginal),]$female_sex_vaginal <- 0
total_msm[is.na(total_msm$female_vaginal_sex_condom),]$female_vaginal_sex_condom <- 0
total_msm[is.na(total_msm$female_vaginal_sex_hiv),]$female_vaginal_sex_hiv <- 0
total_msm[is.na(total_msm$female_vaginal_sex_idu),]$female_vaginal_sex_idu <- 0

# remove unlabelled data
total_msm <- total_msm[!is.na(total_msm$master_sti),]

# state likely doesn't matter, but fill in missing data with default
total_msm[is.na(total_msm$state),]$state <- 0
```

Our next step is to start imputing our data. We can begin by making some strong assumptions for information that we have good data about. For instance, if there is a missing value for `taken_pep`, but the case reports that they have not heard of PEP, we can safetly impute that the case has not taken PEP.

```{r cleaning_functions}

# cleaning functions were moved to external file to improve readability
# library(glue) is a dependency
# import all the cleaning functions contained in cleaning_functions.R
source("H:/Machine Learning for CDS/cleaning_functions.R")

# call taken_pep_cleanup from cleaning_functions.R on total_msm
taken_pep_cleanup(total_msm)
summary(total_msm$taken_pep) # still returns 58 NA values

# subset out remaining missing values
problem_peps <- total_msm[is.na(total_msm$taken_pep),]

# call taken_prep_cleanup from cleaning_functions.R on total_msm
taken_prep_cleanup(total_msm)
summary(total_msm$taken_prep) # still returns 58 NA values

# call sexless_cases_cleanup from cleaning_functions.R on total_msm
sexless_cases_cleanup(total_msm)

# call hiv_features_cleanup on total_msm
hiv_positive_cleanup(total_msm)

# we can impute all missing gender values from column sex_partners, which asks respondents to describe themselves
gender_cleanup(total_msm)
summary(total_msm$gender) # still returns 58 NA values

# set missing values for last_hiv_test to unknown
total_msm[, c('last_hiv_test')][is.na(total_msm[, c('last_hiv_test')])] <- 7

# if has had HIV test within memory, mark as not HIV positive (applies to 7 cases)
total_msm[(is.na(total_msm$hiv_positive) & (total_msm$last_hiv_test != 7) & (total_msm$hiv_test == 1)),]$hiv_positive <- 0

as_tibble(select(total_msm[is.na(total_msm$hiv_positive),], c('hiv_risk', 'hiv_test', 'last_hiv_test', 'hiv_positive')))

missing_hiv_risk <- select(total_msm[is.na(total_msm$hiv_risk),], c('hiv_risk', 'hiv_test', 'last_hiv_test', 'hiv_positive'))
as_tibble(missing_hiv_risk)


oral_sex_cleanup(total_msm)

missing_female_sex <- select(total_msm[is.na(total_msm$oral_sex_condom),], c('oral_sex_condom','sex_partners','total_partners','male_oral_sex', 'female_oral_sex', 'oral_sex_hiv', 'oral_sex_idu','oral_sex_condom'))
as_tibble(missing_female_sex) #325

# DELETE THIS LINE AFTER 7/5/19 -------------
# on a whim, let's try our analysis again selecting only for complete cases. This is likely going to be underpowered af
total_msm <- total_msm[complete.cases(total_msm) == TRUE,]
```

Setting categorical variables as factors.

```{r}
# gender
total_msm$gender = factor(total_msm$gender,levels=c("0","1","2","3","4","5"))
levels(total_msm$gender)=c("Male","Female","Transgender (Male to Female)","Transgender (Female to Male)","Genderqueer/Agender/Nonbinary","Other")

# sex partners
total_msm$sex_partners = factor(total_msm$sex_partners,levels=c("0","1","2","3","4","5","7","8","9","10","11","12","13"))
levels(total_msm$sex_partners)=c("I am a woman who only has sex with women","I am a woman who only has sex with men","I am a woman who has sex with both men and women","I am a man who only has sex with women","I am a man who only has sex with other men","I am a man who has sex with both men and women","I am a transman who only has sex with other women","I am a transman who only has sex with other men","I am a transman who has sex with both men and women","I am a transwoman who only has sex with other women","I am a transwoman who only has sex with other men","I am a transwoman who has sex with other men and women","Unknown")

# state
total_msm$state = factor(total_msm$state,levels=c("0","1","2","3"))
levels(total_msm$state)=c("Rhode Island","Massachusetts","Connecticut","Other")

# race
total_msm$race = factor(total_msm$race,levels=c("0","1","2","3","4","5","6","7","8"))
levels(total_msm$race)=c("American Indian/Alaska Native","Asian","Native Hawaiian or Other Pacific Islander","Black or African American","White/Caucasian","Cape Verdean","More Than One Race","Other","Not Answered")

total_msm$ethnicity = factor(total_msm$ethnicity,levels=c("0","1","2","3"))
total_msm$insurance = factor(total_msm$insurance,levels=c("1","0"))
total_msm$hiv_test = factor(total_msm$hiv_test,levels=c("1","0"))
total_msm$last_hiv_test = factor(total_msm$last_hiv_test,levels=c("0","1","2","3","4","5","6","7"))
total_msm$hiv_positive = factor(total_msm$hiv_positive,levels=c("1","0"))
total_msm$hiv_risk = factor(total_msm$hiv_risk,levels=c("1","2","3","4","0"))
total_msm$self_exchanges_sex = factor(total_msm$self_exchanges_sex,levels=c("1","0"))
total_msm$sex_with_exchanges_sex = factor(total_msm$sex_with_exchanges_sex,levels=c("1","0"))
total_msm$anonymous_partner = factor(total_msm$anonymous_partner,levels=c("1","0"))
total_msm$intoxicated = factor(total_msm$intoxicated,levels=c("1","0"))
total_msm$unknown_status = factor(total_msm$unknown_status,levels=c("1","0"))
total_msm$std_last_year = factor(total_msm$std_last_year,levels=c("1","0"))
total_msm$amphetamine = factor(total_msm$amphetamine,levels=c("1","0"))
total_msm$poppers = factor(total_msm$poppers,levels=c("1","0"))
total_msm$transfusion_transplant = factor(total_msm$transfusion_transplant,levels=c("1","0"))
total_msm$intranasal_cocaine = factor(total_msm$intranasal_cocaine,levels=c("1","0"))
total_msm$incarcerated = factor(total_msm$incarcerated,levels=c("1","0"))
total_msm$forced_sex = factor(total_msm$forced_sex,levels=c("1","0"))
total_msm$sex_hepatitis_c = factor(total_msm$sex_hepatitis_c,levels=c("1","0"))
total_msm$tattoo = factor(total_msm$tattoo,levels=c("1","0"))
total_msm$std_ever = factor(total_msm$std_ever,levels=c("1","0"))
total_msm$std_name___0 = factor(total_msm$std_name___0,levels=c("0","1"))
total_msm$std_name___1 = factor(total_msm$std_name___1,levels=c("0","1"))
total_msm$std_name___2 = factor(total_msm$std_name___2,levels=c("0","1"))
total_msm$std_name___3 = factor(total_msm$std_name___3,levels=c("0","1"))
total_msm$std_name___4 = factor(total_msm$std_name___4,levels=c("0","1"))
total_msm$std_name___5 = factor(total_msm$std_name___5,levels=c("0","1"))
total_msm$std_name___6 = factor(total_msm$std_name___6,levels=c("0","1"))
total_msm$std_name___7 = factor(total_msm$std_name___7,levels=c("0","1"))
total_msm$idu = factor(total_msm$idu,levels=c("1","0"))
total_msm$heard_pep = factor(total_msm$heard_pep,levels=c("1","0"))
total_msm$taken_pep = factor(total_msm$taken_pep,levels=c("1","0"))
total_msm$prep_heard = factor(total_msm$prep_heard,levels=c("1","0"))
total_msm$taken_prep = factor(total_msm$taken_prep,levels=c("1","0"))
#total_msm$hiv_result = factor(total_msm$hiv_result,levels=c("0","1","2","3"))
total_msm$hiv_test_type___0 = factor(total_msm$hiv_test_type___0,levels=c("0","1"))
total_msm$hiv_test_type___1 = factor(total_msm$hiv_test_type___1,levels=c("0","1"))
total_msm$hcv_result = factor(total_msm$hcv_result,levels=c("0","1","2","3"))
total_msm$master_sti = factor(total_msm$master_sti,levels=c("0", "1"))

levels(total_msm$ethnicity)=c("Hispanic or Latino","NOT Hispanic or Latino","Other","Not Answered")
levels(total_msm$insurance)=c("Yes","No")
levels(total_msm$hiv_test)=c("Yes","No")
levels(total_msm$last_hiv_test)=c("Less than a month ago","1-3 months ago","4-6 months ago","7-12 months ago","1-2 years ago","2-5 years ago","over five years ago","unsure")
levels(total_msm$hiv_positive)=c("Yes","No")
levels(total_msm$hiv_risk)=c("None","Low","Medium","High","Not Applicable")
levels(total_msm$self_exchanges_sex)=c("Yes","No")
levels(total_msm$sex_with_exchanges_sex)=c("Yes","No")
levels(total_msm$anonymous_partner)=c("Yes","No")
levels(total_msm$intoxicated)=c("Yes","No")
levels(total_msm$unknown_status)=c("Yes","No")
levels(total_msm$std_last_year)=c("Yes","No")
levels(total_msm$amphetamine)=c("Yes","No")
levels(total_msm$poppers)=c("Yes","No")
levels(total_msm$transfusion_transplant)=c("Yes","No")
levels(total_msm$intranasal_cocaine)=c("Yes","No")
levels(total_msm$incarcerated)=c("Yes","No")
levels(total_msm$forced_sex)=c("Yes","No")
levels(total_msm$sex_hepatitis_c)=c("Yes","No")
levels(total_msm$tattoo)=c("Yes","No")
levels(total_msm$std_ever)=c("Yes","No")
levels(total_msm$std_name___0)=c("Unchecked","Checked")
levels(total_msm$std_name___1)=c("Unchecked","Checked")
levels(total_msm$std_name___2)=c("Unchecked","Checked")
levels(total_msm$std_name___3)=c("Unchecked","Checked")
levels(total_msm$std_name___4)=c("Unchecked","Checked")
levels(total_msm$std_name___5)=c("Unchecked","Checked")
levels(total_msm$std_name___6)=c("Unchecked","Checked")
levels(total_msm$std_name___7)=c("Unchecked","Checked")
levels(total_msm$idu)=c("Yes","No")
levels(total_msm$heard_pep)=c("Yes","No")
levels(total_msm$taken_pep)=c("Yes","No")
levels(total_msm$prep_heard)=c("Yes","No")
levels(total_msm$taken_prep)=c("Yes","No")
levels(total_msm$hiv_test_type___0)=c("Unchecked","Checked")
levels(total_msm$hiv_test_type___1)=c("Unchecked","Checked")
levels(total_msm$hcv_result)=c("Negative","Positive","Not performed","Pending")
levels(total_msm$master_sti) = c("No", "Yes")
```

Date variables (such as `visit_date`) can create issues, especially for one-hot encoding. This can be fixed by converting the date variable to a number or category. For this analysis, we will be subgrouping the dates into seasons using the function `getSeason()`. We will then remove the `visit_date` column. A future analysis could look at the time difference from Pride.

```{r}
library(dplyr)

# fix date feature by turning into seasonal data
getSeason <- function(DATES) {
    WS <- as.Date("2012-12-15", format = "%Y-%m-%d") # Winter Solstice
    SE <- as.Date("2012-3-15",  format = "%Y-%m-%d") # Spring Equinox
    SS <- as.Date("2012-6-15",  format = "%Y-%m-%d") # Summer Solstice
    FE <- as.Date("2012-9-15",  format = "%Y-%m-%d") # Fall Equinox

    # Convert dates from any year to 2012 dates
    d <- as.Date(strftime(DATES, format="2012-%m-%d"))

    ifelse (d >= WS | d < SE, "Winter",
      ifelse (d >= SE & d < SS, "Spring",
        ifelse (d >= SS & d < FE, "Summer", "Fall")))
}

# apply above function to create season column
total_msm <- dplyr::mutate(total_msm, season = getSeason(visit_date))
total_msm <- select(total_msm, -c('visit_date')) # had to remove exact visit date as it interfered with ohe
```

It's time to SMOTE this data hunny! We should do it here (where data are )

Next, we need to fix up the remaining missing data.

```{r, eval=FALSE, include=FALSE}
library(rpart)
original <- total_msm

class_mod <- rpart(hiv_risk ~ . - master_sti, data=total_msm[!is.na(total_msm$hiv_risk), ], method="class", na.action=na.omit)
hiv_risk_pred <- predict(class_mod, total_msm[is.na(total_msm$hiv_risk),])
actuals <- original$hiv_risk[is.na(total_msm$hiv_risk)]
predicted <- as.numeric(colnames(hiv_risk_pred)[apply(hiv_risk_pred, 1, which.max)])
mean(actuals != predicted)
```

```{r}
library(caret)

total_msm_un_ohe <- total_msm

# one hot encode
dmy <- dummyVars(" ~ .", data = total_msm, drop2nd = TRUE)
total_msm_trsf <- data.frame(predict(dmy, newdata=total_msm))
total_msm_trsf <- subset(total_msm_trsf, select = -c(master_sti.No))
names(total_msm_trsf)[names(total_msm_trsf) == 'master_sti.Yes'] <- 'master_sti'
total_msm <- total_msm_trsf



```


### Imputation

Unfortunately, our dataset isn't 100% complete. This isn't the end of the world though. We can do imputation on some of the data. NOTE: 6/25/19 - this chunk has been disabled as this kind of imputation is bad.

```{r impute_missing_data, eval=FALSE, include=FALSE}
library(imputeTS)

# remove rows that do no have a label in them (n = )
total_msm <- total_msm[!is.na(total_msm$master_sti),]
total_msm$race <- na.interpolation(total_msm$race, option = "stine")
total_msm$total_partners <- na.interpolation(total_msm$total_partners, option = "stine")
#total_msm$gender <- na.interpolation(total_msm$gender, option = "stine")
#total_msm$sex_assigned_birth <- na.interpolation(total_msm$sex_assigned_birth, option = "stine")
#total_msm$sexual_identify <- na.interpolation(total_msm$sexual_identify, option = "stine")
total_msm$ethnicity <- na.interpolation(total_msm$ethnicity, option = "stine")
total_msm$insurance <- na.interpolation(total_msm$insurance, option = "stine")
total_msm$hiv_risk <- na.interpolation(total_msm$hiv_risk, option = "stine")
total_msm$hiv_test <- na.interpolation(total_msm$hiv_test, option = "stine")
total_msm$self_exchanges_sex <- na.interpolation(total_msm$self_exchanges_sex, option = "stine")
total_msm$sex_with_exchanges_sex <- na.interpolation(total_msm$sex_with_exchanges_sex, option = "stine")
total_msm$anonymous_partner <- na.interpolation(total_msm$anonymous_partner, option = "stine")
total_msm$intoxicated <- na.interpolation(total_msm$intoxicated, option = "stine")
total_msm$unknown_status <- na.interpolation(total_msm$unknown_status, option = "stine")
total_msm$std_last_year <- na.interpolation(total_msm$std_last_year, option = "stine")
```

### Split into testing and training set

In order to avoid the issue of overfitting, we have to split out data into a test and a train subset. We will start with a good default split of train:test - 70:30.  

```{r create_test_train}
# Split our data into a Train and Test set
# Training set : Test set = 70:30 (random)
# TODO: Try to make sampling better (i.e. balance over time)

# select 70% of the sample as training
train <- sample(nrow(total_msm), 0.7*nrow(total_msm), replace = FALSE)

# create our training and testing sets
trainSet <- total_msm[train,]
trainSet_un_ohe <- total_msm_un_ohe[train,]
table(trainSet$master_sti)

testSet <- total_msm[-train,]
testSet_un_ohe <- total_msm_un_ohe[-train,]
table(testSet$master_sti)

```

### Principle Component Analysis

After a meeting with Neil Sarkar, it was suggested that my model may have some issues if there are many variables that are pointing in one direction. A potential solution for this overweighting is to implement logistic regression and PCA. 

```{r, PCA Analysis}
library(factoextra)
library(FactoMineR)

# compute PCA
#res <- prcomp(trainSet, scale = FALSE)
res <- FAMD(trainSet_un_ohe, ncp = 10, graph = TRUE)

# visualize eigenvalues in scree plot
# pct of variances explaned by each principle component
fviz_eig(res)

# graph of variables
fviz_pca_var(res,
             col.ar = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)

```

### Random Forest

```{r random_forest_analysis}

# begin to train our model
library(randomForest)
library(caret)
library(mlbench)

# define the control using a random forest selection function
controlvar <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(trainSet, trainLabel, sizes=c(1:140), rfeControl=controlvar)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))

# define control
ctrl <- trainControl(method="repeatedcv", number = 10,
                          allowParallel=TRUE)

model_rf <- randomForest(master_sti ~ ., 
                       data = trainSet, 
                       importance = TRUE,
                       trControl = ctrl,
                       tuneLength = 10)

pred1 <- predict(model_rf, testSet)

# calculate and plot the area under the curve
auc <- roc(response=as.factor(testSet$master_sti), predictor=as.numeric(pred1),smoothed=TRUE,ci=TRUE)
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)

pred1_cut <- as.numeric(predict(model_rf, data.matrix(testSet)) > 0.5)
confusionMatrix(as.factor(pred1_cut), as.factor(testSet$master_sti), positive="1")

# print out confusion matrix and variable importance plot
print(model_rf)
plot(varImp(model_rf))
```

### Tree Bagging

```{r tree_bagging_analysis}
library(DMwR)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
library(partykit)



# run treebagging model
model_cart <- train(master_sti ~ ., 
                 data=trainSet, 
                 method="treebag", 
                 trControl=ctrl,
                 tuneLength=10,
                 importance=TRUE)



# predict on the test set
pred2 <- predict(model_cart$finalModel, testSet)
# calculate and plot the area under the curve
auc <- roc(response=as.factor(testSet$master_sti), predictor=as.numeric(pred2),smoothed=TRUE,ci=TRUE)
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)

pred2_cut <- as.numeric(predict(model_cart$finalModel, data.matrix(testSet)) > 0.5)
confusionMatrix(as.factor(pred2_cut), as.factor(testSet$master_sti), positive="1")

# print out confusion matrix and variable importance plot
print(model_cart)
plot(varImp(model_cart))
```


### GBM
```{r}
train.gbm <- train(master_sti ~ ., 
                   data=trainSet,
                   method="gbm",
                   verbose=F,
                   trControl=ctrl)

# predict on the test set
pred_gbm <- predict(train.gbm$finalModel, testSet, n.trees=train.gbm$bestTune$n.trees)
# calculate and plot the area under the curve
auc <- roc(response=as.factor(testSet$master_sti), predictor=as.numeric(pred_gbm),smoothed=TRUE,ci=TRUE)
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)

```
### SMOTE to correct for unbalanced classes
```{r, SMOTE for Balance}
#library(DMwR)
#trainSet$master_sti <- as.factor(trainSet$master_sti)
#trainSet <- SMOTE(master_sti ~ ., trainSet, perc.over = 100, perc.under=200)
#trainSet$master_sti <- as.numeric(trainSet$master_sti)

#prop.table(table(trainSet$master_sti))
```

### XGBoost

XGBoost requires the labels and the testing sets to be separate. Therefore we have to separate them out for this analysis.

```{r xgboost_analysis}
# xgboost
library(xgboost)
library(caret)

# define the testing and training labels
trainLabel <- as.numeric(trainSet$master_sti)
testLabel <- as.numeric(testSet$master_sti)

# eliminate the label from the testing and training set
trainSet[,c("master_sti")] <- list(NULL)
testSet[,c("master_sti")] <- list(NULL)

# get sum number of positive and negative cases to weight model
#sumwneg <- sum()

# run the xgboost analysis
xgb <- xgboost(data = data.matrix(trainSet), label=trainLabel, eta = 0.05, gamma = 0, max_depth=25, nround=25,
               subsample=0.5, colsample_bytree=0.5, seed=1, eval_metric="error", eval.metric ="logloss",
               scale_pos_weight=3.786, 
               objective="binary:logistic",
               num_class=1, nthread=3)
xgb

# predict on the testSet 
y_pred <- predict(xgb, data.matrix(testSet))
y_pred_cut <- as.numeric(predict(xgb, data.matrix(testSet)) > 0.5)

# print out the confusion matrix
confuMat <- confusionMatrix(as.factor(y_pred_cut), as.factor(testLabel), positive="1")
confuMat

# plot variable importance plot
mat <- xgb.importance(feature_names = colnames(trainSet), model=xgb)
xgb.plot.importance(importance_matrix = mat[1:70])
```

Alright, our result isn't terrible. We have a model accuracy of `r round(confuMat$overall[1], digit=3)`, but we might be able to do better. One way to go about improving this model would be to make a more educated guess about the threshold value for our model. Originally we set our threshold value as 0.5. We can observe the impact of the threshold value on the accuracy of our model using an ROC curve.

``` {r roc_curve}
library(pROC)

roc_curve <- roc(response=testLabel,predictor=y_pred, smoothed=TRUE,ci=TRUE)
plot(roc_curve, print.thres="best")
abline(v=1,lty=2)
abline(h=1,lty=2)
text(.90,.97,labels="Ideal Model")
points(1,1,pch="0",cex=1.5)

library(ROCR)
xgb.pred <- prediction(y_pred, testLabel)
xgb.perf <- performance(xgb.pred, "tpr", "fpr")

plot(xgb.perf,
     avg="threshold",
     colorize=TRUE,
     lwd=1,
     main="ROC Curve w/ Thresholds",
     print.cutoffs.at=seq(0,1,by=0.05),
     text.adj=c(-0.5,0.5),
     text.cex=0.5)
grid(col="lightgray")
axis(1, at=seq(0,1,by=0.1))
axis(2, at=seq(0,1,by=0.1))
abline(v=c(0.1,0.3,0.5,0.7,0.9),col="lightgray",lty="dotted")
abline(h=c(0.1,0.3,0.5,0.7,0.9),col="lightgray",lty="dotted")
lines(x=c(0,1),y=c(0,1),col="black",lty="dotted")
```

This curve suggests to us that our actual best threshold cutoff would be at `r coords(roc_curve, "best", ret = "threshold")`. The AUC for this is `r round(roc_curve$auc, 3)`. Running the same xgboost again, with an adapted treshold gets us.

```{r xgboost_analysis_pROC}
library(pROC)
# predict on the testSet 
y_pred <- predict(xgb, data.matrix(testSet))
y_pred_cut <- as.numeric(predict(xgb, data.matrix(testSet)) > coords(roc_curve, "best", ret = "threshold"))

# print out the confusion matrix
confuMat <- confusionMatrix(as.factor(testLabel), as.factor(y_pred_cut), positive = levels(as.factor(testLabel))[2])
confuMat
```

# Some more tuning
```{r, eval=FALSE, include=FALSE}
library(caret)
library(xgboost)
library(readr)
library(dplyr)
library(tidyr)

# xgboost fitting with arbitrary parameters
xgb_params_1 = list(
  objective = "binary:logistic",                                               # binary classification
  eta = 0.01,                                                                  # learning rate
  max.depth = 3,                                                               # max tree depth
  eval_metric = "auc"                                                          # evaluation/loss metric
)

# fit the model with the arbitrary parameters specified above
xgb_1 = xgboost(data = as.matrix(trainSet),
                label = trainLabel,
                params = xgb_params_1,
                nrounds = 100,                                                 # max number of trees to build
                verbose = TRUE,                                         
                print.every.n = 1,
                early.stop.round = 10                                          # stop if no improvement within 10 trees
)

# cross-validate xgboost to get the accurate measure of error
xgb_cv_1 = xgb.cv(params = xgb_params_1,
                  data =as.matrix(trainSet),
                  label = trainLabel,
                  nrounds = 100, 
                  nfold = 5,                                                   # number of folds in K-fold
                  prediction = TRUE,                                           # return the prediction using the final model 
                  showsd = TRUE,                                               # standard deviation of loss across folds
                  stratified = TRUE,                                           # sample is unbalanced; use stratified sampling
                  verbose = TRUE,
                  print.every.n = 1, 
                  early.stop.round = 20
)

# set up the cross-validated hyper-parameter search
xgb_grid_1 = expand.grid(
  nrounds = 1000,
  eta = c(0.01, 0.001, 0.0001),
  max_depth = c(2, 4, 6, 8, 10),
  gamma = 1,
  colsample_bytree = c(0.1, 0.2, 0.3, 0.4),
  min_child_weight = c(2, 4, 6, 8, 10),
  subsample = 1
)

# pack the training control parameters
xgb_trcontrol_1 = trainControl(
  method = "cv",
  number = 5,
  verboseIter = TRUE,
  returnData = FALSE,
  returnResamp = "all",                                                        # save losses across all models
  classProbs = TRUE,                                                           # set to TRUE for AUC to be computed
  summaryFunction = twoClassSummary,
  allowParallel = TRUE
)

trainLabel <- as.factor(trainLabel)

levels(trainLabel)[1] <- "Negative"
levels(trainLabel)[2] <- "Positive"
# train the model for each parameter combination in the grid, 
#   using CV to evaluate
xgb_train_1 = train(
  x = as.matrix(trainSet),
  y = trainLabel,
  trControl = xgb_trcontrol_1,
  tuneGrid = xgb_grid_1,
  method = "xgbTree"
)

# scatter plot of the AUC against max_depth and eta
ggplot(xgb_train_1$results, aes(x = as.factor(eta), y = max_depth, size = ROC, color = ROC)) + 
  geom_point() + 
  theme_bw() + 
  scale_size_continuous(guide = "none")


```

Okay so this code block took about an hour to run, so it has been deactivated. The results are as follows: `Fitting nrounds = 1000, max_depth = 6, eta = 0.001, gamma = 1, colsample_bytree = 0.4, min_child_weight = 4, subsample = 1 on full training set`.

```{r, eval=FALSE, include=FALSE}
library(purrr)
trainLabel <- as.double(map(as.double(trainLabel), ~ .x - 1))

xgb2 <- xgboost(data = data.matrix(trainSet), label=trainLabel, eta=0.001, gamma=1, max_depth=6, nround=1000,
               subsample=1, colsample_bytree=0.4, min_child_weight=4,seed=1, eval_metric="error", eval.metric ="logloss",
               scale_pos_weight=3.786, 
               objective="binary:logistic",
               num_class=1, nthread=3)
xgb2

# predict on the testSet 
y_pred <- predict(xgb2, data.matrix(testSet))
y_pred_cut <- as.numeric(predict(xgb2, data.matrix(testSet)) > 0.5)

# print out the confusion matrix
confuMat <- confusionMatrix(as.factor(testLabel), as.factor(y_pred_cut), positive="1")
confuMat

```

Okay. That took forever to implement and it has a middling accuracy, though the Kappa value is higher than usual. Something to consider is implementing a Support Vector Model. We can try to do that below.

```{r}
library(e1071)
library(dplyr)
library(bestNormalize)
library(caret)

total_msm_svm <- total_msm[-2119,]

# select 70% of the sample as training
train_svm <- sample(nrow(total_msm_svm), 0.5*nrow(total_msm_svm), replace = FALSE)

col_list <- c('age', 'total_partners', 'male_oral_sex', 'female_oral_sex', 'oral_sex_condom', 'oral_sex_hiv', 'male_anal_insertive',
              'male_anal_sex_condom', 'male_anal_sex_idu', 'male_anal_sex_hiv', 'oral_sex_idu', 'female_sex_vaginal', 'female_vaginal_sex_condom',
              'female_vaginal_sex_hiv', 'female_vaginal_sex_idu', 'male_anal_sex_both', 'male_anal_receptive')


total_msm_svm[col_list] <- lapply(total_msm_svm[col_list], function(n) c(bestNormalize(n)$x.t))


# create our training and testing sets
trainSet_svm <- total_msm_svm[train_svm,]

testSet_svm <- total_msm_svm[-train_svm,]

# obj <- tune(svm, master_sti~., data = trainSet_svm, kernel="radial", 
#                  ranges = list(#gamma=c(0.1,0.5,1,2,4), 
#                                cost = c(0.1,1,10)
#                                ), 
#                  class.weights= c("0" = 1, "1" = 5))
# 
# summary(obj)
# plot(obj)

classifier = svm(formula = master_sti ~ ., 
                 data = trainSet_svm, 
                 type = 'C-classification', 
                 kernel = 'radial',
                 cost = 5,
                 class.weights= c("0" = 1, "1" = 2)) 

y_pred_svm <- predict(classifier, newdata = testSet_svm[,-137])

# calculate and plot the area under the curve
auc <- roc(response=as.factor(testSet_svm$master_sti), predictor=as.numeric(y_pred_svm),smoothed=TRUE,ci=TRUE)
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)

confusionMatrix(as.factor(testSet_svm[,137]), as.factor(y_pred_svm), positive = "1") 



plot(classifier, trainSet_svm, male_anal_sex_condom ~ male_anal_insertive)
plot(classifier, trainSet_svm, male_anal_sex_condom ~ male_anal_receptive)
plot(classifier, trainSet_svm, age ~ male_anal_insertive)
plot(classifier, trainSet_svm, age ~ male_anal_receptive)
plot(classifier, trainSet_svm, total_partners ~ male_anal_insertive)
plot(classifier, trainSet_svm, total_partners ~ male_anal_receptive)
plot(classifier, trainSet_svm, male_anal_receptive ~ male_anal_insertive)



```

# Neural Nets

Another implementation to try is neural nets. 

```{r}
library(neuralnet)
library(tidyverse)


as_tibble(trainSet)

nn <- neuralnet(master_sti ~ ., 
               data = trainSet_svm, hidden=c(3), act.fct = "logistic", linear.output = FALSE)

plot(nn)
```




# External Code Appendix
Some functions used to clean the data were abstracted into a different file referenced above. This file, `cleaning_functions.R` is displayed below.

```{r,cleaning_functions, code = readLines("cleaning_functions.R")}
```